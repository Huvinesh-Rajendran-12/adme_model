{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb182896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982ae74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../ADME.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07047c68-d60f-484d-98ec-c9e7ffed3142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Internal ID</th><th>Vendor ID</th><th>SMILES</th><th>CollectionName</th><th>LOG HLM_CLint (mL/min/kg)</th><th>LOG MDR1-MDCK ER (B-A/A-B)</th><th>LOG SOLUBILITY PH 6.8 (ug/mL)</th><th>LOG PLASMA PROTEIN BINDING (HUMAN) (% unbound)</th><th>LOG PLASMA PROTEIN BINDING (RAT) (% unbound)</th><th>LOG RLM_CLint (mL/min/kg)</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Mol1&quot;</td><td>&quot;317714313&quot;</td><td>&quot;CNc1cc(Nc2cccn(-c3ccccn3)c2=O)…</td><td>&quot;emolecules&quot;</td><td>0.675687</td><td>1.493167</td><td>0.089905</td><td>0.991226</td><td>0.518514</td><td>1.392169</td></tr><tr><td>&quot;Mol2&quot;</td><td>&quot;324056965&quot;</td><td>&quot;CCOc1cc2nn(CCC(C)(C)O)cc2cc1NC…</td><td>&quot;emolecules&quot;</td><td>0.675687</td><td>1.04078</td><td>0.550228</td><td>0.099681</td><td>0.268344</td><td>1.02792</td></tr><tr><td>&quot;Mol3&quot;</td><td>&quot;304005766&quot;</td><td>&quot;CN(c1ncc(F)cn1)[C@H]1CCCNC1&quot;</td><td>&quot;emolecules&quot;</td><td>0.675687</td><td>-0.358806</td><td>null</td><td>2.0</td><td>2.0</td><td>1.02792</td></tr><tr><td>&quot;Mol4&quot;</td><td>&quot;194963090&quot;</td><td>&quot;CC(C)(Oc1ccc(-c2cnc(N)c(-c3ccc…</td><td>&quot;emolecules&quot;</td><td>0.675687</td><td>1.026662</td><td>1.657056</td><td>-1.158015</td><td>-1.403403</td><td>1.02792</td></tr><tr><td>&quot;Mol5&quot;</td><td>&quot;324059015&quot;</td><td>&quot;CC(C)(O)CCn1cc2cc(NC(=O)c3cccc…</td><td>&quot;emolecules&quot;</td><td>0.99638</td><td>1.010597</td><td>null</td><td>1.015611</td><td>1.092264</td><td>1.629093</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ Internal  ┆ Vendor ID ┆ SMILES    ┆ Collectio ┆ … ┆ LOG SOLUB ┆ LOG       ┆ LOG       ┆ LOG RLM_ │\n",
       "│ ID        ┆ ---       ┆ ---       ┆ nName     ┆   ┆ ILITY PH  ┆ PLASMA    ┆ PLASMA    ┆ CLint    │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ 6.8       ┆ PROTEIN   ┆ PROTEIN   ┆ (mL/min/ │\n",
       "│ str       ┆           ┆           ┆ str       ┆   ┆ (ug/mL)   ┆ BINDING   ┆ BINDING   ┆ kg)      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ---       ┆ (HU…      ┆ (RA…      ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ ---       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ f64       ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Mol1      ┆ 317714313 ┆ CNc1cc(Nc ┆ emolecule ┆ … ┆ 0.089905  ┆ 0.991226  ┆ 0.518514  ┆ 1.392169 │\n",
       "│           ┆           ┆ 2cccn(-c3 ┆ s         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ ccccn3)c2 ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ =O)…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Mol2      ┆ 324056965 ┆ CCOc1cc2n ┆ emolecule ┆ … ┆ 0.550228  ┆ 0.099681  ┆ 0.268344  ┆ 1.02792  │\n",
       "│           ┆           ┆ n(CCC(C)( ┆ s         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ C)O)cc2cc ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ 1NC…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Mol3      ┆ 304005766 ┆ CN(c1ncc( ┆ emolecule ┆ … ┆ null      ┆ 2.0       ┆ 2.0       ┆ 1.02792  │\n",
       "│           ┆           ┆ F)cn1)[C@ ┆ s         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ H]1CCCNC1 ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Mol4      ┆ 194963090 ┆ CC(C)(Oc1 ┆ emolecule ┆ … ┆ 1.657056  ┆ -1.158015 ┆ -1.403403 ┆ 1.02792  │\n",
       "│           ┆           ┆ ccc(-c2cn ┆ s         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ c(N)c(-c3 ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ ccc…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Mol5      ┆ 324059015 ┆ CC(C)(O)C ┆ emolecule ┆ … ┆ null      ┆ 1.015611  ┆ 1.092264  ┆ 1.629093 │\n",
       "│           ┆           ┆ Cn1cc2cc( ┆ s         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ NC(=O)c3c ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ ccc…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0cab45-9ce6-4cc5-910d-34a931b2fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype.is_numeric():\n",
    "        df = df.with_columns(pl.col(column).fill_null(df[column].mean()))\n",
    "    else:\n",
    "        df = df.with_columns(pl.col(column).fill_null(df[column].mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff489e1-7fe2-4ced-b77f-419b6b46d847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Internal ID</th><th>Vendor ID</th><th>SMILES</th><th>CollectionName</th><th>LOG HLM_CLint (mL/min/kg)</th><th>LOG MDR1-MDCK ER (B-A/A-B)</th><th>LOG SOLUBILITY PH 6.8 (ug/mL)</th><th>LOG PLASMA PROTEIN BINDING (HUMAN) (% unbound)</th><th>LOG PLASMA PROTEIN BINDING (RAT) (% unbound)</th><th>LOG RLM_CLint (mL/min/kg)</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 10)\n",
       "┌────────────┬───────────┬────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Internal   ┆ Vendor ID ┆ SMILES ┆ Collection ┆ … ┆ LOG SOLUB ┆ LOG       ┆ LOG       ┆ LOG       │\n",
       "│ ID         ┆ ---       ┆ ---    ┆ Name       ┆   ┆ ILITY PH  ┆ PLASMA    ┆ PLASMA    ┆ RLM_CLint │\n",
       "│ ---        ┆ u32       ┆ u32    ┆ ---        ┆   ┆ 6.8       ┆ PROTEIN   ┆ PROTEIN   ┆ (mL/min/k │\n",
       "│ u32        ┆           ┆        ┆ u32        ┆   ┆ (ug/mL)   ┆ BINDING   ┆ BINDING   ┆ g)        │\n",
       "│            ┆           ┆        ┆            ┆   ┆ ---       ┆ (HU…      ┆ (RA…      ┆ ---       │\n",
       "│            ┆           ┆        ┆            ┆   ┆ u32       ┆ ---       ┆ ---       ┆ u32       │\n",
       "│            ┆           ┆        ┆            ┆   ┆           ┆ u32       ┆ u32       ┆           │\n",
       "╞════════════╪═══════════╪════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0          ┆ 0         ┆ 0      ┆ 0          ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "└────────────┴───────────┴────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee70215-3af3-4f0d-a1e0-38ee8880c1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Internal ID',\n",
       " 'Vendor ID',\n",
       " 'SMILES',\n",
       " 'CollectionName',\n",
       " 'LOG HLM_CLint (mL/min/kg)',\n",
       " 'LOG MDR1-MDCK ER (B-A/A-B)',\n",
       " 'LOG SOLUBILITY PH 6.8 (ug/mL)',\n",
       " 'LOG PLASMA PROTEIN BINDING (HUMAN) (% unbound)',\n",
       " 'LOG PLASMA PROTEIN BINDING (RAT) (% unbound)',\n",
       " 'LOG RLM_CLint (mL/min/kg)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080cfed6-8743-4e81-aa26-3b23183fe71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"LOG HLM_CLint (mL/min/kg)\":\"log_hlm_clint\", \"LOG MDR1-MDCK ER (B-A/A-B)\":\"log_mdr1_mdck\", \"LOG SOLUBILITY PH 6.8 (ug/mL)\":\"log_solubility_ph\", \"LOG PLASMA PROTEIN BINDING (HUMAN) (% unbound)\":\"log_plasma_protein_human\", \"LOG PLASMA PROTEIN BINDING (RAT) (% unbound)\":\"log_plasma_protein_rat\", \"LOG RLM_CLint (mL/min/kg)\":\"log_rlm_clint\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b437adf-5f6c-4cf2-9c0c-54126a38e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Internal ID',\n",
       " 'Vendor ID',\n",
       " 'SMILES',\n",
       " 'CollectionName',\n",
       " 'log_hlm_clint',\n",
       " 'log_mdr1_mdck',\n",
       " 'log_solubility_ph',\n",
       " 'log_plasma_protein_human',\n",
       " 'log_plasma_protein_rat',\n",
       " 'log_rlm_clint']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05aeef31-9136-4ed8-b04f-dd9aec28351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df['SMILES'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0613d62-104d-44af-bf9c-66c2fb4bbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMILES Encoding\n",
    "vocab = list(set(\"\".join(smiles)))  # Get unique characters from SMILES strings\n",
    "char_to_idx = {c: i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24232691-7732-46ec-8cd9-4adeb0eb0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_smiles(smiles_list):\n",
    "    encoded_smiles = []\n",
    "    for smi in smiles_list:\n",
    "        encoded_smi = [char_to_idx[c] for c in smi]\n",
    "        encoded_smiles.append(encoded_smi)\n",
    "    return encoded_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383736d7-5117-4ab2-acab-e9f0b42a28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to have the same length (required for batch processing)\n",
    "def pad_sequences(sequences, max_length=None):\n",
    "    if max_length is None:\n",
    "        max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        padded_seq = seq + [0] * (max_length - len(seq))\n",
    "        padded_sequences.append(padded_seq)\n",
    "    return torch.tensor(padded_sequences, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3c6517-d371-4705-b909-4d9c09258913",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_smiles = pad_sequences(encode_smiles(smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b78e4b-5554-415c-b0ab-6a17782f2c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17, 26, 16,  ...,  0,  0,  0],\n",
       "        [17, 17, 15,  ...,  0,  0,  0],\n",
       "        [17, 26, 23,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [26, 17, 23,  ...,  0,  0,  0],\n",
       "        [17, 17, 17,  ...,  0,  0,  0],\n",
       "        [17, 16, 11,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81964192-3a9c-42d5-9878-799f1f3334e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adme_values = torch.tensor(df[[\"log_hlm_clint\", \"log_mdr1_mdck\", \"log_solubility_ph\", \"log_plasma_protein_human\", \"log_plasma_protein_rat\", \"log_rlm_clint\"]].to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "444e225b-2e0f-4eb2-90db-a17661a15e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6757,  1.4932,  0.0899,  0.9912,  0.5185,  1.3922],\n",
       "        [ 0.6757,  1.0408,  0.5502,  0.0997,  0.2683,  1.0279],\n",
       "        [ 0.6757, -0.3588,  1.2599,  2.0000,  2.0000,  1.0279],\n",
       "        ...,\n",
       "        [ 0.8638,  0.3978,  1.2599,  0.7657,  0.7642,  2.2562],\n",
       "        [ 0.8814,  0.3978,  1.2599,  0.7657,  0.7642,  2.2562],\n",
       "        [ 1.5071,  0.3978,  1.2599,  0.7657,  0.7642,  2.2562]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adme_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "295ede06-4fcf-4904-9bc2-8c92c2d09684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADMEDataset(Dataset):\n",
    "    def __init__(self, encoded_smiles, adme_values):\n",
    "        self.encoded_smiles = encoded_smiles\n",
    "        self.adme_values = adme_values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_smiles[idx], self.adme_values[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75070c74-f0e7-4247-8aa4-8501430a476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = ADMEDataset(encoded_smiles, adme_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8b508c1-806d-4adb-977d-7d5e521fa123",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70b669e8-95ae-42d3-9f37-e2eef263e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)  # No need to shuffle validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06c96213-dad9-4aef-b52d-a19680bf977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADMEMT_DNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=10, hidden_dim=64, num_tasks=6):\n",
    "        super(ADMEMT_DNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.task_heads = nn.ModuleList([nn.Linear(hidden_dim // 2, 1) for _ in range(num_tasks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x[:, -1, :]  # Take the last hidden state for each sequence\n",
    "        outputs = torch.cat([head(x) for head in self.task_heads], dim=1)  # Concatenate outputs along the feature dimension\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e5ff001-b08f-47c1-8a66-9762386416bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ADMEMT_DNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f6b1c04-76c5-43da-b04f-fa2cbef263b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression tasks\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8969993-92e8-4ead-ad30-42707c8ecebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.5672\n",
      "Validation Loss: 1.6031\n",
      "Epoch [2/100], Loss: 1.5663\n",
      "Validation Loss: 1.6053\n",
      "Epoch [3/100], Loss: 1.5681\n",
      "Validation Loss: 1.6064\n",
      "Epoch [4/100], Loss: 1.5691\n",
      "Validation Loss: 1.6009\n",
      "Epoch [5/100], Loss: 1.5639\n",
      "Validation Loss: 1.6038\n",
      "Epoch [6/100], Loss: 1.5586\n",
      "Validation Loss: 1.6038\n",
      "Epoch [7/100], Loss: 1.5602\n",
      "Validation Loss: 1.5999\n",
      "Epoch [8/100], Loss: 1.5599\n",
      "Validation Loss: 1.6035\n",
      "Epoch [9/100], Loss: 1.5643\n",
      "Validation Loss: 1.6037\n",
      "Epoch [10/100], Loss: 1.5620\n",
      "Validation Loss: 1.6038\n",
      "Epoch [11/100], Loss: 1.5665\n",
      "Validation Loss: 1.6008\n",
      "Epoch [12/100], Loss: 1.5544\n",
      "Validation Loss: 1.6007\n",
      "Epoch [13/100], Loss: 1.5645\n",
      "Validation Loss: 1.6000\n",
      "Epoch [14/100], Loss: 1.5620\n",
      "Validation Loss: 1.6024\n",
      "Epoch [15/100], Loss: 1.5663\n",
      "Validation Loss: 1.6032\n",
      "Epoch [16/100], Loss: 1.5650\n",
      "Validation Loss: 1.6021\n",
      "Epoch [17/100], Loss: 1.5616\n",
      "Validation Loss: 1.6089\n",
      "Epoch [18/100], Loss: 1.5575\n",
      "Validation Loss: 1.6031\n",
      "Epoch [19/100], Loss: 1.5605\n",
      "Validation Loss: 1.6049\n",
      "Epoch [20/100], Loss: 1.5687\n",
      "Validation Loss: 1.6050\n",
      "Epoch [21/100], Loss: 1.5647\n",
      "Validation Loss: 1.6003\n",
      "Epoch [22/100], Loss: 1.5566\n",
      "Validation Loss: 1.6050\n",
      "Epoch [23/100], Loss: 1.5625\n",
      "Validation Loss: 1.6088\n",
      "Epoch [24/100], Loss: 1.5600\n",
      "Validation Loss: 1.6015\n",
      "Epoch [25/100], Loss: 1.5586\n",
      "Validation Loss: 1.6060\n",
      "Epoch [26/100], Loss: 1.5526\n",
      "Validation Loss: 1.6013\n",
      "Epoch [27/100], Loss: 1.5562\n",
      "Validation Loss: 1.6026\n",
      "Epoch [28/100], Loss: 1.5602\n",
      "Validation Loss: 1.6054\n",
      "Epoch [29/100], Loss: 1.5544\n",
      "Validation Loss: 1.6054\n",
      "Epoch [30/100], Loss: 1.5583\n",
      "Validation Loss: 1.6033\n",
      "Epoch [31/100], Loss: 1.5587\n",
      "Validation Loss: 1.6022\n",
      "Epoch [32/100], Loss: 1.5610\n",
      "Validation Loss: 1.6021\n",
      "Epoch [33/100], Loss: 1.5561\n",
      "Validation Loss: 1.6050\n",
      "Epoch [34/100], Loss: 1.5542\n",
      "Validation Loss: 1.6020\n",
      "Epoch [35/100], Loss: 1.5561\n",
      "Validation Loss: 1.6044\n",
      "Epoch [36/100], Loss: 1.5537\n",
      "Validation Loss: 1.6048\n",
      "Epoch [37/100], Loss: 1.5521\n",
      "Validation Loss: 1.6046\n",
      "Epoch [38/100], Loss: 1.5592\n",
      "Validation Loss: 1.6014\n",
      "Epoch [39/100], Loss: 1.5542\n",
      "Validation Loss: 1.6044\n",
      "Epoch [40/100], Loss: 1.5548\n",
      "Validation Loss: 1.6044\n",
      "Epoch [41/100], Loss: 1.5561\n",
      "Validation Loss: 1.6004\n",
      "Epoch [42/100], Loss: 1.5557\n",
      "Validation Loss: 1.6041\n",
      "Epoch [43/100], Loss: 1.5609\n",
      "Validation Loss: 1.6006\n",
      "Epoch [44/100], Loss: 1.5609\n",
      "Validation Loss: 1.6018\n",
      "Epoch [45/100], Loss: 1.5495\n",
      "Validation Loss: 1.6017\n",
      "Epoch [46/100], Loss: 1.5581\n",
      "Validation Loss: 1.6078\n",
      "Epoch [47/100], Loss: 1.5537\n",
      "Validation Loss: 1.6012\n",
      "Epoch [48/100], Loss: 1.5538\n",
      "Validation Loss: 1.6039\n",
      "Epoch [49/100], Loss: 1.5527\n",
      "Validation Loss: 1.6080\n",
      "Epoch [50/100], Loss: 1.5581\n",
      "Validation Loss: 1.6084\n",
      "Epoch [51/100], Loss: 1.5526\n",
      "Validation Loss: 1.6008\n",
      "Epoch [52/100], Loss: 1.5567\n",
      "Validation Loss: 1.6094\n",
      "Epoch [53/100], Loss: 1.5641\n",
      "Validation Loss: 1.6058\n",
      "Epoch [54/100], Loss: 1.5513\n",
      "Validation Loss: 1.6013\n",
      "Epoch [55/100], Loss: 1.5565\n",
      "Validation Loss: 1.6021\n",
      "Epoch [56/100], Loss: 1.5503\n",
      "Validation Loss: 1.6019\n",
      "Epoch [57/100], Loss: 1.5559\n",
      "Validation Loss: 1.6042\n",
      "Epoch [58/100], Loss: 1.5567\n",
      "Validation Loss: 1.6052\n",
      "Epoch [59/100], Loss: 1.5555\n",
      "Validation Loss: 1.6045\n",
      "Epoch [60/100], Loss: 1.5520\n",
      "Validation Loss: 1.6072\n",
      "Epoch [61/100], Loss: 1.5546\n",
      "Validation Loss: 1.6015\n",
      "Epoch [62/100], Loss: 1.5537\n",
      "Validation Loss: 1.6045\n",
      "Epoch [63/100], Loss: 1.5571\n",
      "Validation Loss: 1.6049\n",
      "Epoch [64/100], Loss: 1.5557\n",
      "Validation Loss: 1.6022\n",
      "Epoch [65/100], Loss: 1.5549\n",
      "Validation Loss: 1.6032\n",
      "Epoch [66/100], Loss: 1.5529\n",
      "Validation Loss: 1.6016\n",
      "Epoch [67/100], Loss: 1.5514\n",
      "Validation Loss: 1.6041\n",
      "Epoch [68/100], Loss: 1.5530\n",
      "Validation Loss: 1.6059\n",
      "Epoch [69/100], Loss: 1.5525\n",
      "Validation Loss: 1.6016\n",
      "Epoch [70/100], Loss: 1.5517\n",
      "Validation Loss: 1.6051\n",
      "Epoch [71/100], Loss: 1.5499\n",
      "Validation Loss: 1.6031\n",
      "Epoch [72/100], Loss: 1.5581\n",
      "Validation Loss: 1.6041\n",
      "Epoch [73/100], Loss: 1.5551\n",
      "Validation Loss: 1.6021\n",
      "Epoch [74/100], Loss: 1.5507\n",
      "Validation Loss: 1.6022\n",
      "Epoch [75/100], Loss: 1.5509\n",
      "Validation Loss: 1.6037\n",
      "Epoch [76/100], Loss: 1.5538\n",
      "Validation Loss: 1.6036\n",
      "Epoch [77/100], Loss: 1.5520\n",
      "Validation Loss: 1.6033\n",
      "Epoch [78/100], Loss: 1.5534\n",
      "Validation Loss: 1.6002\n",
      "Epoch [79/100], Loss: 1.5508\n",
      "Validation Loss: 1.6044\n",
      "Epoch [80/100], Loss: 1.5524\n",
      "Validation Loss: 1.6056\n",
      "Epoch [81/100], Loss: 1.5517\n",
      "Validation Loss: 1.6042\n",
      "Epoch [82/100], Loss: 1.5569\n",
      "Validation Loss: 1.6040\n",
      "Epoch [83/100], Loss: 1.5550\n",
      "Validation Loss: 1.6036\n",
      "Epoch [84/100], Loss: 1.5522\n",
      "Validation Loss: 1.6038\n",
      "Epoch [85/100], Loss: 1.5481\n",
      "Validation Loss: 1.6052\n",
      "Epoch [86/100], Loss: 1.5544\n",
      "Validation Loss: 1.6062\n",
      "Epoch [87/100], Loss: 1.5534\n",
      "Validation Loss: 1.6035\n",
      "Epoch [88/100], Loss: 1.5498\n",
      "Validation Loss: 1.6035\n",
      "Epoch [89/100], Loss: 1.5506\n",
      "Validation Loss: 1.6057\n",
      "Epoch [90/100], Loss: 1.5513\n",
      "Validation Loss: 1.6028\n",
      "Epoch [91/100], Loss: 1.5496\n",
      "Validation Loss: 1.6052\n",
      "Epoch [92/100], Loss: 1.5479\n",
      "Validation Loss: 1.6026\n",
      "Epoch [93/100], Loss: 1.5517\n",
      "Validation Loss: 1.6043\n",
      "Epoch [94/100], Loss: 1.5446\n",
      "Validation Loss: 1.6034\n",
      "Epoch [95/100], Loss: 1.5511\n",
      "Validation Loss: 1.6016\n",
      "Epoch [96/100], Loss: 1.5542\n",
      "Validation Loss: 1.6034\n",
      "Epoch [97/100], Loss: 1.5525\n",
      "Validation Loss: 1.6025\n",
      "Epoch [98/100], Loss: 1.5513\n",
      "Validation Loss: 1.6041\n",
      "Epoch [99/100], Loss: 1.5515\n",
      "Validation Loss: 1.6023\n",
      "Epoch [100/100], Loss: 1.5491\n",
      "Validation Loss: 1.6043\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "num_tasks = 6\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for smiles_batch, adme_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(smiles_batch)\n",
    "        outputs = outputs.view(-1, num_tasks)\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(num_tasks):\n",
    "            loss += criterion(outputs[:, i], adme_batch[:, i])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()  # Accumulate loss for the epoch\n",
    "\n",
    "    # Print and log average epoch loss\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation step (optional, but recommended)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for smiles_batch, adme_batch in val_loader:\n",
    "            outputs = model(smiles_batch)\n",
    "            outputs = outputs.view(-1, num_tasks)\n",
    "\n",
    "            loss = 0\n",
    "            for i in range(num_tasks):\n",
    "                loss += criterion(outputs[:, i], adme_batch[:, i])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    logging.info(f\"Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c499084a-76d6-4cf6-8bdf-e6acdfabc827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: MSE = 0.3589, R^2 = -0.0048\n",
      "Task 2: MSE = 0.3294, R^2 = -0.0024\n",
      "Task 3: MSE = 0.2689, R^2 = -0.0009\n",
      "Task 4: MSE = 0.0412, R^2 = -0.0001\n",
      "Task 5: MSE = 0.0312, R^2 = -0.0060\n",
      "Task 6: MSE = 0.5192, R^2 = -0.0084\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "total_loss = 0\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "    for smiles_batch, adme_batch in val_loader:\n",
    "        outputs = model(smiles_batch)\n",
    "        outputs = outputs.view(-1, num_tasks)  # Reshape outputs\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = 0\n",
    "        for i in range(num_tasks):\n",
    "            loss += criterion(outputs[:, i], adme_batch[:, i])\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and targets for later metric calculation\n",
    "        all_predictions.append(outputs)\n",
    "        all_targets.append(adme_batch)\n",
    "\n",
    "# Calculate average loss over all batches\n",
    "avg_loss = total_loss / len(val_loader)\n",
    "\n",
    "# Concatenate predictions and targets for metric calculation\n",
    "all_predictions = torch.cat(all_predictions, dim=0).numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "\n",
    "# Calculate metrics for each task\n",
    "for i in range(num_tasks):\n",
    "    mse = mean_squared_error(all_targets[:, i], all_predictions[:, i])\n",
    "    r2 = r2_score(all_targets[:, i], all_predictions[:, i])\n",
    "    print(f\"Task {i + 1}: MSE = {mse:.4f}, R^2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afd5e25c-7317-4891-b0e5-39bfb3527f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_string = \"CC(=O)Oc1ccccc1C(=O)O\"  # Example SMILES\n",
    "encoded_smile = pad_sequences([[char_to_idx[c] for c in smile_string]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c6e3bf6-9664-4fa1-81fa-236a14279fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    output = model(encoded_smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05fccb7c-71ca-4883-9fbe-3995b569ce0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8276425004005432,\n",
       " 0.16862380504608154,\n",
       " 0.8602256178855896,\n",
       " 0.7115737199783325,\n",
       " 0.7278763055801392,\n",
       " 1.098250389099121]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d0c68-4f88-483b-b48c-7cb07d3cd39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
